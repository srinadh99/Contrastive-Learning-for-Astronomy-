{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a0a3d0c6-b4c2-4e9d-af21-360bebe74afe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Labels: ['GALAXY' 'STAR']\n",
      "\n",
      "\n",
      "Train shape: (120007, 5, 32, 32)\n",
      "Val shape  : (19992, 5, 32, 32)\n",
      "Test shape : (20000, 5, 32, 32)\n",
      "Device: cuda:0\n",
      "\n",
      "=== Self-supervised contrastive pretraining (IMAGE ONLY) ===\n",
      "[Epoch 1] grad norm (projector[0].weight): 5.3470e-02\n",
      "[Contrastive] Epoch [1/300] - Train Loss: 5.0870, Val Loss: 3.0774\n",
      "[Epoch 2] grad norm (projector[0].weight): 1.0070e+00\n",
      "[Contrastive] Epoch [2/300] - Train Loss: 2.3927, Val Loss: 2.0131\n",
      "[Epoch 3] grad norm (projector[0].weight): 1.2277e+00\n",
      "[Contrastive] Epoch [3/300] - Train Loss: 1.8736, Val Loss: 1.5555\n",
      "[Epoch 4] grad norm (projector[0].weight): 1.4187e+00\n",
      "[Contrastive] Epoch [4/300] - Train Loss: 1.4380, Val Loss: 1.2892\n",
      "[Epoch 5] grad norm (projector[0].weight): 1.0319e+00\n",
      "[Contrastive] Epoch [5/300] - Train Loss: 1.2372, Val Loss: 1.1297\n",
      "[Epoch 6] grad norm (projector[0].weight): 8.9122e-01\n",
      "[Contrastive] Epoch [6/300] - Train Loss: 1.1202, Val Loss: 1.0535\n",
      "[Epoch 7] grad norm (projector[0].weight): 8.0968e-01\n",
      "[Contrastive] Epoch [7/300] - Train Loss: 1.0304, Val Loss: 0.9658\n",
      "[Epoch 8] grad norm (projector[0].weight): 7.0330e-01\n",
      "[Contrastive] Epoch [8/300] - Train Loss: 0.9648, Val Loss: 0.8854\n",
      "[Epoch 9] grad norm (projector[0].weight): 5.5607e-01\n",
      "[Contrastive] Epoch [9/300] - Train Loss: 0.8923, Val Loss: 0.8285\n",
      "[Epoch 10] grad norm (projector[0].weight): 6.7713e-01\n",
      "[Contrastive] Epoch [10/300] - Train Loss: 0.8437, Val Loss: 0.8043\n",
      "[Epoch 11] grad norm (projector[0].weight): 6.7211e-01\n",
      "[Contrastive] Epoch [11/300] - Train Loss: 0.8059, Val Loss: 0.7444\n",
      "[Epoch 12] grad norm (projector[0].weight): 5.0027e-01\n",
      "[Contrastive] Epoch [12/300] - Train Loss: 0.7571, Val Loss: 0.6737\n",
      "[Epoch 13] grad norm (projector[0].weight): 4.2861e-01\n",
      "[Contrastive] Epoch [13/300] - Train Loss: 0.6656, Val Loss: 0.6105\n",
      "[Epoch 14] grad norm (projector[0].weight): 4.9826e-01\n",
      "[Contrastive] Epoch [14/300] - Train Loss: 0.6163, Val Loss: 0.5791\n",
      "[Epoch 15] grad norm (projector[0].weight): 3.9795e-01\n",
      "[Contrastive] Epoch [15/300] - Train Loss: 0.5924, Val Loss: 0.5592\n",
      "[Epoch 16] grad norm (projector[0].weight): 3.3940e-01\n",
      "[Contrastive] Epoch [16/300] - Train Loss: 0.5708, Val Loss: 0.5287\n",
      "[Epoch 17] grad norm (projector[0].weight): 3.5004e-01\n",
      "[Contrastive] Epoch [17/300] - Train Loss: 0.5562, Val Loss: 0.5203\n",
      "[Epoch 18] grad norm (projector[0].weight): 3.1783e-01\n",
      "[Contrastive] Epoch [18/300] - Train Loss: 0.5398, Val Loss: 0.5158\n",
      "[Epoch 19] grad norm (projector[0].weight): 2.9699e-01\n",
      "[Contrastive] Epoch [19/300] - Train Loss: 0.5318, Val Loss: 0.4962\n",
      "[Epoch 20] grad norm (projector[0].weight): 2.3009e-01\n",
      "[Contrastive] Epoch [20/300] - Train Loss: 0.5206, Val Loss: 0.4890\n",
      "[Epoch 21] grad norm (projector[0].weight): 2.4615e-01\n",
      "[Contrastive] Epoch [21/300] - Train Loss: 0.5116, Val Loss: 0.4767\n",
      "[Epoch 22] grad norm (projector[0].weight): 2.5371e-01\n",
      "[Contrastive] Epoch [22/300] - Train Loss: 0.5039, Val Loss: 0.4775\n",
      "[Epoch 23] grad norm (projector[0].weight): 2.3970e-01\n",
      "[Contrastive] Epoch [23/300] - Train Loss: 0.4959, Val Loss: 0.4814\n",
      "[Epoch 24] grad norm (projector[0].weight): 2.8433e-01\n",
      "[Contrastive] Epoch [24/300] - Train Loss: 0.4921, Val Loss: 0.4579\n",
      "[Epoch 25] grad norm (projector[0].weight): 2.1215e-01\n",
      "[Contrastive] Epoch [25/300] - Train Loss: 0.4841, Val Loss: 0.4566\n",
      "[Epoch 26] grad norm (projector[0].weight): 2.3830e-01\n",
      "[Contrastive] Epoch [26/300] - Train Loss: 0.4771, Val Loss: 0.4638\n",
      "[Epoch 27] grad norm (projector[0].weight): 2.9866e-01\n",
      "[Contrastive] Epoch [27/300] - Train Loss: 0.4696, Val Loss: 0.4399\n",
      "[Epoch 28] grad norm (projector[0].weight): 2.4291e-01\n",
      "[Contrastive] Epoch [28/300] - Train Loss: 0.4632, Val Loss: 0.4430\n",
      "[Epoch 29] grad norm (projector[0].weight): 2.7212e-01\n",
      "[Contrastive] Epoch [29/300] - Train Loss: 0.4575, Val Loss: 0.4353\n",
      "[Epoch 30] grad norm (projector[0].weight): 2.6879e-01\n",
      "[Contrastive] Epoch [30/300] - Train Loss: 0.4531, Val Loss: 0.4283\n",
      "[Epoch 31] grad norm (projector[0].weight): 2.1011e-01\n",
      "[Contrastive] Epoch [31/300] - Train Loss: 0.4439, Val Loss: 0.4241\n",
      "[Epoch 32] grad norm (projector[0].weight): 1.9238e-01\n",
      "[Contrastive] Epoch [32/300] - Train Loss: 0.4409, Val Loss: 0.4219\n",
      "[Epoch 33] grad norm (projector[0].weight): 1.8914e-01\n",
      "[Contrastive] Epoch [33/300] - Train Loss: 0.4384, Val Loss: 0.4071\n",
      "[Epoch 34] grad norm (projector[0].weight): 1.9103e-01\n",
      "[Contrastive] Epoch [34/300] - Train Loss: 0.4335, Val Loss: 0.4119\n",
      "[Epoch 35] grad norm (projector[0].weight): 1.7889e-01\n",
      "[Contrastive] Epoch [35/300] - Train Loss: 0.4275, Val Loss: 0.4144\n",
      "[Epoch 36] grad norm (projector[0].weight): 1.8483e-01\n",
      "[Contrastive] Epoch [36/300] - Train Loss: 0.4254, Val Loss: 0.4149\n",
      "[Epoch 37] grad norm (projector[0].weight): 2.2559e-01\n",
      "[Contrastive] Epoch [37/300] - Train Loss: 0.4202, Val Loss: 0.3979\n",
      "[Epoch 38] grad norm (projector[0].weight): 1.7318e-01\n",
      "[Contrastive] Epoch [38/300] - Train Loss: 0.4161, Val Loss: 0.3893\n",
      "[Epoch 39] grad norm (projector[0].weight): 1.9542e-01\n",
      "[Contrastive] Epoch [39/300] - Train Loss: 0.4116, Val Loss: 0.3990\n",
      "[Epoch 40] grad norm (projector[0].weight): 2.0636e-01\n",
      "[Contrastive] Epoch [40/300] - Train Loss: 0.4109, Val Loss: 0.3874\n",
      "[Epoch 41] grad norm (projector[0].weight): 1.9570e-01\n",
      "[Contrastive] Epoch [41/300] - Train Loss: 0.4066, Val Loss: 0.3944\n",
      "[Epoch 42] grad norm (projector[0].weight): 1.9549e-01\n",
      "[Contrastive] Epoch [42/300] - Train Loss: 0.4045, Val Loss: 0.3808\n",
      "[Epoch 43] grad norm (projector[0].weight): 1.5494e-01\n",
      "[Contrastive] Epoch [43/300] - Train Loss: 0.4009, Val Loss: 0.3798\n",
      "[Epoch 44] grad norm (projector[0].weight): 1.6107e-01\n",
      "[Contrastive] Epoch [44/300] - Train Loss: 0.3975, Val Loss: 0.3786\n",
      "[Epoch 45] grad norm (projector[0].weight): 1.8418e-01\n",
      "[Contrastive] Epoch [45/300] - Train Loss: 0.3954, Val Loss: 0.3951\n",
      "[Epoch 46] grad norm (projector[0].weight): 1.9294e-01\n",
      "[Contrastive] Epoch [46/300] - Train Loss: 0.3941, Val Loss: 0.3690\n",
      "[Epoch 47] grad norm (projector[0].weight): 1.4544e-01\n",
      "[Contrastive] Epoch [47/300] - Train Loss: 0.3886, Val Loss: 0.3760\n",
      "[Epoch 48] grad norm (projector[0].weight): 1.7245e-01\n",
      "[Contrastive] Epoch [48/300] - Train Loss: 0.3847, Val Loss: 0.3686\n",
      "[Epoch 49] grad norm (projector[0].weight): 1.4929e-01\n",
      "[Contrastive] Epoch [49/300] - Train Loss: 0.3851, Val Loss: 0.3674\n",
      "[Epoch 50] grad norm (projector[0].weight): 1.5624e-01\n",
      "[Contrastive] Epoch [50/300] - Train Loss: 0.3818, Val Loss: 0.3642\n",
      "[Epoch 51] grad norm (projector[0].weight): 1.4225e-01\n",
      "[Contrastive] Epoch [51/300] - Train Loss: 0.3794, Val Loss: 0.3579\n",
      "[Epoch 52] grad norm (projector[0].weight): 1.2155e-01\n",
      "[Contrastive] Epoch [52/300] - Train Loss: 0.3778, Val Loss: 0.3649\n",
      "[Epoch 53] grad norm (projector[0].weight): 1.6408e-01\n",
      "[Contrastive] Epoch [53/300] - Train Loss: 0.3771, Val Loss: 0.3666\n",
      "[Epoch 54] grad norm (projector[0].weight): 1.5986e-01\n",
      "[Contrastive] Epoch [54/300] - Train Loss: 0.3745, Val Loss: 0.3588\n",
      "[Epoch 55] grad norm (projector[0].weight): 1.2725e-01\n",
      "[Contrastive] Epoch [55/300] - Train Loss: 0.3724, Val Loss: 0.3571\n",
      "[Epoch 56] grad norm (projector[0].weight): 1.4249e-01\n",
      "[Contrastive] Epoch [56/300] - Train Loss: 0.3708, Val Loss: 0.3471\n",
      "[Epoch 57] grad norm (projector[0].weight): 1.2295e-01\n",
      "[Contrastive] Epoch [57/300] - Train Loss: 0.3668, Val Loss: 0.3504\n",
      "[Epoch 58] grad norm (projector[0].weight): 1.2331e-01\n",
      "[Contrastive] Epoch [58/300] - Train Loss: 0.3668, Val Loss: 0.3503\n",
      "[Epoch 59] grad norm (projector[0].weight): 1.1689e-01\n",
      "[Contrastive] Epoch [59/300] - Train Loss: 0.3655, Val Loss: 0.3476\n",
      "[Epoch 60] grad norm (projector[0].weight): 1.1008e-01\n",
      "[Contrastive] Epoch [60/300] - Train Loss: 0.3623, Val Loss: 0.3493\n",
      "[Epoch 61] grad norm (projector[0].weight): 1.2537e-01\n",
      "[Contrastive] Epoch [61/300] - Train Loss: 0.3608, Val Loss: 0.3422\n",
      "[Epoch 62] grad norm (projector[0].weight): 1.0772e-01\n",
      "[Contrastive] Epoch [62/300] - Train Loss: 0.3594, Val Loss: 0.3414\n",
      "[Epoch 63] grad norm (projector[0].weight): 1.0703e-01\n",
      "[Contrastive] Epoch [63/300] - Train Loss: 0.3550, Val Loss: 0.3392\n",
      "[Epoch 64] grad norm (projector[0].weight): 1.0645e-01\n",
      "[Contrastive] Epoch [64/300] - Train Loss: 0.3543, Val Loss: 0.3386\n",
      "[Epoch 65] grad norm (projector[0].weight): 1.2199e-01\n",
      "[Contrastive] Epoch [65/300] - Train Loss: 0.3533, Val Loss: 0.3375\n",
      "[Epoch 66] grad norm (projector[0].weight): 1.1129e-01\n",
      "[Contrastive] Epoch [66/300] - Train Loss: 0.3524, Val Loss: 0.3346\n",
      "[Epoch 67] grad norm (projector[0].weight): 1.0021e-01\n",
      "[Contrastive] Epoch [67/300] - Train Loss: 0.3508, Val Loss: 0.3297\n",
      "[Epoch 68] grad norm (projector[0].weight): 1.0236e-01\n",
      "[Contrastive] Epoch [68/300] - Train Loss: 0.3514, Val Loss: 0.3348\n",
      "[Epoch 69] grad norm (projector[0].weight): 9.7207e-02\n",
      "[Contrastive] Epoch [69/300] - Train Loss: 0.3497, Val Loss: 0.3304\n",
      "[Epoch 70] grad norm (projector[0].weight): 1.0569e-01\n",
      "[Contrastive] Epoch [70/300] - Train Loss: 0.3480, Val Loss: 0.3349\n",
      "[Epoch 71] grad norm (projector[0].weight): 1.1040e-01\n",
      "[Contrastive] Epoch [71/300] - Train Loss: 0.3474, Val Loss: 0.3270\n",
      "[Epoch 72] grad norm (projector[0].weight): 1.0938e-01\n",
      "[Contrastive] Epoch [72/300] - Train Loss: 0.3451, Val Loss: 0.3277\n",
      "[Epoch 73] grad norm (projector[0].weight): 9.8172e-02\n",
      "[Contrastive] Epoch [73/300] - Train Loss: 0.3452, Val Loss: 0.3330\n",
      "[Epoch 74] grad norm (projector[0].weight): 9.6654e-02\n",
      "[Contrastive] Epoch [74/300] - Train Loss: 0.3435, Val Loss: 0.3269\n",
      "[Epoch 75] grad norm (projector[0].weight): 9.9071e-02\n",
      "[Contrastive] Epoch [75/300] - Train Loss: 0.3409, Val Loss: 0.3206\n",
      "[Epoch 76] grad norm (projector[0].weight): 9.2190e-02\n",
      "[Contrastive] Epoch [76/300] - Train Loss: 0.3401, Val Loss: 0.3226\n",
      "[Epoch 77] grad norm (projector[0].weight): 1.0223e-01\n",
      "[Contrastive] Epoch [77/300] - Train Loss: 0.3385, Val Loss: 0.3274\n",
      "[Epoch 78] grad norm (projector[0].weight): 9.3006e-02\n",
      "[Contrastive] Epoch [78/300] - Train Loss: 0.3377, Val Loss: 0.3239\n",
      "[Epoch 79] grad norm (projector[0].weight): 9.3803e-02\n",
      "[Contrastive] Epoch [79/300] - Train Loss: 0.3374, Val Loss: 0.3231\n",
      "[Epoch 80] grad norm (projector[0].weight): 8.6827e-02\n",
      "[Contrastive] Epoch [80/300] - Train Loss: 0.3364, Val Loss: 0.3215\n",
      "[Epoch 81] grad norm (projector[0].weight): 8.0233e-02\n",
      "[Contrastive] Epoch [81/300] - Train Loss: 0.3346, Val Loss: 0.3185\n",
      "[Epoch 82] grad norm (projector[0].weight): 9.1694e-02\n",
      "[Contrastive] Epoch [82/300] - Train Loss: 0.3341, Val Loss: 0.3221\n",
      "[Epoch 83] grad norm (projector[0].weight): 1.2198e-01\n",
      "[Contrastive] Epoch [83/300] - Train Loss: 0.3339, Val Loss: 0.3190\n",
      "[Epoch 84] grad norm (projector[0].weight): 9.2284e-02\n",
      "[Contrastive] Epoch [84/300] - Train Loss: 0.3324, Val Loss: 0.3204\n",
      "[Epoch 85] grad norm (projector[0].weight): 9.2380e-02\n",
      "[Contrastive] Epoch [85/300] - Train Loss: 0.3312, Val Loss: 0.3133\n",
      "[Epoch 86] grad norm (projector[0].weight): 8.5486e-02\n",
      "[Contrastive] Epoch [86/300] - Train Loss: 0.3308, Val Loss: 0.3101\n",
      "[Epoch 87] grad norm (projector[0].weight): 7.7822e-02\n",
      "[Contrastive] Epoch [87/300] - Train Loss: 0.3288, Val Loss: 0.3112\n",
      "[Epoch 88] grad norm (projector[0].weight): 7.4068e-02\n",
      "[Contrastive] Epoch [88/300] - Train Loss: 0.3279, Val Loss: 0.3149\n",
      "[Epoch 89] grad norm (projector[0].weight): 8.9543e-02\n",
      "[Contrastive] Epoch [89/300] - Train Loss: 0.3275, Val Loss: 0.3154\n",
      "[Epoch 90] grad norm (projector[0].weight): 8.3471e-02\n",
      "[Contrastive] Epoch [90/300] - Train Loss: 0.3268, Val Loss: 0.3093\n",
      "[Epoch 91] grad norm (projector[0].weight): 7.4611e-02\n",
      "[Contrastive] Epoch [91/300] - Train Loss: 0.3266, Val Loss: 0.3080\n",
      "[Epoch 92] grad norm (projector[0].weight): 7.8547e-02\n",
      "[Contrastive] Epoch [92/300] - Train Loss: 0.3248, Val Loss: 0.3145\n",
      "[Epoch 93] grad norm (projector[0].weight): 9.2036e-02\n",
      "[Contrastive] Epoch [93/300] - Train Loss: 0.3243, Val Loss: 0.3105\n",
      "[Epoch 94] grad norm (projector[0].weight): 7.9308e-02\n",
      "[Contrastive] Epoch [94/300] - Train Loss: 0.3235, Val Loss: 0.3073\n",
      "[Epoch 95] grad norm (projector[0].weight): 8.0986e-02\n",
      "[Contrastive] Epoch [95/300] - Train Loss: 0.3215, Val Loss: 0.3052\n",
      "[Epoch 96] grad norm (projector[0].weight): 7.6947e-02\n",
      "[Contrastive] Epoch [96/300] - Train Loss: 0.3213, Val Loss: 0.3050\n",
      "[Epoch 97] grad norm (projector[0].weight): 7.0554e-02\n",
      "[Contrastive] Epoch [97/300] - Train Loss: 0.3196, Val Loss: 0.3073\n",
      "[Epoch 98] grad norm (projector[0].weight): 9.3719e-02\n",
      "[Contrastive] Epoch [98/300] - Train Loss: 0.3207, Val Loss: 0.3130\n",
      "[Epoch 99] grad norm (projector[0].weight): 1.0734e-01\n",
      "[Contrastive] Epoch [99/300] - Train Loss: 0.3191, Val Loss: 0.3017\n",
      "[Epoch 100] grad norm (projector[0].weight): 7.7732e-02\n",
      "[Contrastive] Epoch [100/300] - Train Loss: 0.3178, Val Loss: 0.3042\n",
      "[Epoch 101] grad norm (projector[0].weight): 8.1457e-02\n",
      "[Contrastive] Epoch [101/300] - Train Loss: 0.3179, Val Loss: 0.3039\n",
      "[Epoch 102] grad norm (projector[0].weight): 8.5618e-02\n",
      "[Contrastive] Epoch [102/300] - Train Loss: 0.3162, Val Loss: 0.2986\n",
      "[Epoch 103] grad norm (projector[0].weight): 5.6174e-02\n",
      "[Contrastive] Epoch [103/300] - Train Loss: 0.3151, Val Loss: 0.2985\n",
      "[Epoch 104] grad norm (projector[0].weight): 6.8797e-02\n",
      "[Contrastive] Epoch [104/300] - Train Loss: 0.3143, Val Loss: 0.3020\n",
      "[Epoch 105] grad norm (projector[0].weight): 7.4015e-02\n",
      "[Contrastive] Epoch [105/300] - Train Loss: 0.3149, Val Loss: 0.2950\n",
      "[Epoch 106] grad norm (projector[0].weight): 6.5408e-02\n",
      "[Contrastive] Epoch [106/300] - Train Loss: 0.3133, Val Loss: 0.2964\n",
      "[Epoch 107] grad norm (projector[0].weight): 6.6716e-02\n",
      "[Contrastive] Epoch [107/300] - Train Loss: 0.3117, Val Loss: 0.2971\n",
      "[Epoch 108] grad norm (projector[0].weight): 6.5138e-02\n",
      "[Contrastive] Epoch [108/300] - Train Loss: 0.3116, Val Loss: 0.3003\n",
      "[Epoch 109] grad norm (projector[0].weight): 8.5336e-02\n",
      "[Contrastive] Epoch [109/300] - Train Loss: 0.3109, Val Loss: 0.2955\n",
      "[Epoch 110] grad norm (projector[0].weight): 6.4777e-02\n",
      "[Contrastive] Epoch [110/300] - Train Loss: 0.3106, Val Loss: 0.2986\n",
      "[Epoch 111] grad norm (projector[0].weight): 7.2133e-02\n",
      "[Contrastive] Epoch [111/300] - Train Loss: 0.3090, Val Loss: 0.2960\n",
      "[Epoch 112] grad norm (projector[0].weight): 7.0094e-02\n",
      "[Contrastive] Epoch [112/300] - Train Loss: 0.3082, Val Loss: 0.2929\n",
      "[Epoch 113] grad norm (projector[0].weight): 6.1720e-02\n",
      "[Contrastive] Epoch [113/300] - Train Loss: 0.3083, Val Loss: 0.2929\n",
      "[Epoch 114] grad norm (projector[0].weight): 6.7072e-02\n",
      "[Contrastive] Epoch [114/300] - Train Loss: 0.3069, Val Loss: 0.2892\n",
      "[Epoch 115] grad norm (projector[0].weight): 6.1814e-02\n",
      "[Contrastive] Epoch [115/300] - Train Loss: 0.3058, Val Loss: 0.2935\n",
      "[Epoch 116] grad norm (projector[0].weight): 6.5102e-02\n",
      "[Contrastive] Epoch [116/300] - Train Loss: 0.3052, Val Loss: 0.2952\n",
      "[Epoch 117] grad norm (projector[0].weight): 8.9463e-02\n",
      "[Contrastive] Epoch [117/300] - Train Loss: 0.3040, Val Loss: 0.2899\n",
      "[Epoch 118] grad norm (projector[0].weight): 6.4390e-02\n",
      "[Contrastive] Epoch [118/300] - Train Loss: 0.3038, Val Loss: 0.2873\n",
      "[Epoch 119] grad norm (projector[0].weight): 7.2372e-02\n",
      "[Contrastive] Epoch [119/300] - Train Loss: 0.3026, Val Loss: 0.2873\n",
      "[Epoch 120] grad norm (projector[0].weight): 5.7582e-02\n",
      "[Contrastive] Epoch [120/300] - Train Loss: 0.3022, Val Loss: 0.2853\n",
      "[Epoch 121] grad norm (projector[0].weight): 5.3107e-02\n",
      "[Contrastive] Epoch [121/300] - Train Loss: 0.3017, Val Loss: 0.2843\n",
      "[Epoch 122] grad norm (projector[0].weight): 5.5169e-02\n",
      "[Contrastive] Epoch [122/300] - Train Loss: 0.3015, Val Loss: 0.2881\n",
      "[Epoch 123] grad norm (projector[0].weight): 5.2841e-02\n",
      "[Contrastive] Epoch [123/300] - Train Loss: 0.3005, Val Loss: 0.2856\n",
      "[Epoch 124] grad norm (projector[0].weight): 6.6656e-02\n",
      "[Contrastive] Epoch [124/300] - Train Loss: 0.3003, Val Loss: 0.2847\n",
      "[Epoch 125] grad norm (projector[0].weight): 6.1550e-02\n",
      "[Contrastive] Epoch [125/300] - Train Loss: 0.2995, Val Loss: 0.2867\n",
      "[Epoch 126] grad norm (projector[0].weight): 6.6064e-02\n",
      "[Contrastive] Epoch [126/300] - Train Loss: 0.2990, Val Loss: 0.2842\n",
      "[Epoch 127] grad norm (projector[0].weight): 6.9901e-02\n",
      "[Contrastive] Epoch [127/300] - Train Loss: 0.2993, Val Loss: 0.2843\n",
      "[Epoch 128] grad norm (projector[0].weight): 5.3738e-02\n",
      "[Contrastive] Epoch [128/300] - Train Loss: 0.2979, Val Loss: 0.2813\n",
      "[Epoch 129] grad norm (projector[0].weight): 6.0429e-02\n",
      "[Contrastive] Epoch [129/300] - Train Loss: 0.2972, Val Loss: 0.2837\n",
      "[Epoch 130] grad norm (projector[0].weight): 5.8517e-02\n",
      "[Contrastive] Epoch [130/300] - Train Loss: 0.2985, Val Loss: 0.2835\n",
      "[Epoch 131] grad norm (projector[0].weight): 5.7967e-02\n",
      "[Contrastive] Epoch [131/300] - Train Loss: 0.2979, Val Loss: 0.2825\n",
      "[Epoch 132] grad norm (projector[0].weight): 4.8892e-02\n",
      "[Contrastive] Epoch [132/300] - Train Loss: 0.2976, Val Loss: 0.2821\n",
      "[Epoch 133] grad norm (projector[0].weight): 5.7797e-02\n",
      "[Contrastive] Epoch [133/300] - Train Loss: 0.2963, Val Loss: 0.2823\n",
      "[Epoch 134] grad norm (projector[0].weight): 5.6636e-02\n",
      "[Contrastive] Epoch [134/300] - Train Loss: 0.2955, Val Loss: 0.2829\n",
      "[Epoch 135] grad norm (projector[0].weight): 5.9031e-02\n",
      "[Contrastive] Epoch [135/300] - Train Loss: 0.2956, Val Loss: 0.2819\n",
      "[Epoch 136] grad norm (projector[0].weight): 5.6836e-02\n",
      "[Contrastive] Epoch [136/300] - Train Loss: 0.2965, Val Loss: 0.2781\n",
      "[Epoch 137] grad norm (projector[0].weight): 5.3922e-02\n",
      "[Contrastive] Epoch [137/300] - Train Loss: 0.2944, Val Loss: 0.2836\n",
      "[Epoch 138] grad norm (projector[0].weight): 5.5744e-02\n",
      "[Contrastive] Epoch [138/300] - Train Loss: 0.2948, Val Loss: 0.2801\n",
      "[Epoch 139] grad norm (projector[0].weight): 5.5806e-02\n",
      "[Contrastive] Epoch [139/300] - Train Loss: 0.2943, Val Loss: 0.2813\n",
      "[Epoch 140] grad norm (projector[0].weight): 5.2414e-02\n",
      "[Contrastive] Epoch [140/300] - Train Loss: 0.2928, Val Loss: 0.2826\n",
      "[Epoch 141] grad norm (projector[0].weight): 5.7598e-02\n",
      "[Contrastive] Epoch [141/300] - Train Loss: 0.2936, Val Loss: 0.2802\n",
      "[Epoch 142] grad norm (projector[0].weight): 5.0509e-02\n",
      "[Contrastive] Epoch [142/300] - Train Loss: 0.2941, Val Loss: 0.2781\n",
      "[Epoch 143] grad norm (projector[0].weight): 5.3556e-02\n",
      "[Contrastive] Epoch [143/300] - Train Loss: 0.2936, Val Loss: 0.2769\n",
      "[Epoch 144] grad norm (projector[0].weight): 4.9583e-02\n",
      "[Contrastive] Epoch [144/300] - Train Loss: 0.2931, Val Loss: 0.2821\n",
      "[Epoch 145] grad norm (projector[0].weight): 6.0894e-02\n",
      "[Contrastive] Epoch [145/300] - Train Loss: 0.2914, Val Loss: 0.2767\n",
      "[Epoch 146] grad norm (projector[0].weight): 5.3007e-02\n",
      "[Contrastive] Epoch [146/300] - Train Loss: 0.2920, Val Loss: 0.2777\n",
      "[Epoch 147] grad norm (projector[0].weight): 4.9725e-02\n",
      "[Contrastive] Epoch [147/300] - Train Loss: 0.2910, Val Loss: 0.2792\n",
      "[Epoch 148] grad norm (projector[0].weight): 5.8904e-02\n",
      "[Contrastive] Epoch [148/300] - Train Loss: 0.2917, Val Loss: 0.2744\n",
      "[Epoch 149] grad norm (projector[0].weight): 5.2944e-02\n",
      "[Contrastive] Epoch [149/300] - Train Loss: 0.2908, Val Loss: 0.2777\n",
      "[Epoch 150] grad norm (projector[0].weight): 5.4471e-02\n",
      "[Contrastive] Epoch [150/300] - Train Loss: 0.2907, Val Loss: 0.2785\n",
      "[Epoch 151] grad norm (projector[0].weight): 5.5175e-02\n",
      "[Contrastive] Epoch [151/300] - Train Loss: 0.2900, Val Loss: 0.2752\n",
      "[Epoch 152] grad norm (projector[0].weight): 4.6520e-02\n",
      "[Contrastive] Epoch [152/300] - Train Loss: 0.2907, Val Loss: 0.2765\n",
      "[Epoch 153] grad norm (projector[0].weight): 5.6009e-02\n",
      "[Contrastive] Epoch [153/300] - Train Loss: 0.2894, Val Loss: 0.2757\n",
      "[Epoch 154] grad norm (projector[0].weight): 5.3619e-02\n",
      "[Contrastive] Epoch [154/300] - Train Loss: 0.2897, Val Loss: 0.2812\n",
      "[Epoch 155] grad norm (projector[0].weight): 5.8607e-02\n",
      "[Contrastive] Epoch [155/300] - Train Loss: 0.2907, Val Loss: 0.2759\n",
      "[Epoch 156] grad norm (projector[0].weight): 5.1064e-02\n",
      "[Contrastive] Epoch [156/300] - Train Loss: 0.2896, Val Loss: 0.2716\n",
      "[Epoch 157] grad norm (projector[0].weight): 5.5467e-02\n",
      "[Contrastive] Epoch [157/300] - Train Loss: 0.2879, Val Loss: 0.2732\n",
      "[Epoch 158] grad norm (projector[0].weight): 4.6664e-02\n",
      "[Contrastive] Epoch [158/300] - Train Loss: 0.2895, Val Loss: 0.2758\n",
      "[Epoch 159] grad norm (projector[0].weight): 4.6774e-02\n",
      "[Contrastive] Epoch [159/300] - Train Loss: 0.2886, Val Loss: 0.2769\n",
      "[Epoch 160] grad norm (projector[0].weight): 5.2680e-02\n",
      "[Contrastive] Epoch [160/300] - Train Loss: 0.2879, Val Loss: 0.2759\n",
      "[Epoch 161] grad norm (projector[0].weight): 5.7626e-02\n",
      "[Contrastive] Epoch [161/300] - Train Loss: 0.2871, Val Loss: 0.2701\n",
      "[Epoch 162] grad norm (projector[0].weight): 5.4119e-02\n",
      "[Contrastive] Epoch [162/300] - Train Loss: 0.2871, Val Loss: 0.2732\n",
      "[Epoch 163] grad norm (projector[0].weight): 4.9432e-02\n",
      "[Contrastive] Epoch [163/300] - Train Loss: 0.2858, Val Loss: 0.2748\n",
      "[Epoch 164] grad norm (projector[0].weight): 5.6031e-02\n",
      "[Contrastive] Epoch [164/300] - Train Loss: 0.2865, Val Loss: 0.2734\n",
      "[Epoch 165] grad norm (projector[0].weight): 5.1711e-02\n",
      "[Contrastive] Epoch [165/300] - Train Loss: 0.2869, Val Loss: 0.2723\n",
      "[Epoch 166] grad norm (projector[0].weight): 4.5453e-02\n",
      "[Contrastive] Epoch [166/300] - Train Loss: 0.2852, Val Loss: 0.2722\n",
      "[Epoch 167] grad norm (projector[0].weight): 4.6623e-02\n",
      "[Contrastive] Epoch [167/300] - Train Loss: 0.2852, Val Loss: 0.2703\n",
      "[Epoch 168] grad norm (projector[0].weight): 3.7439e-02\n",
      "[Contrastive] Epoch [168/300] - Train Loss: 0.2858, Val Loss: 0.2709\n",
      "[Epoch 169] grad norm (projector[0].weight): 4.2705e-02\n",
      "[Contrastive] Epoch [169/300] - Train Loss: 0.2864, Val Loss: 0.2727\n",
      "[Epoch 170] grad norm (projector[0].weight): 3.8971e-02\n",
      "[Contrastive] Epoch [170/300] - Train Loss: 0.2854, Val Loss: 0.2683\n",
      "[Epoch 171] grad norm (projector[0].weight): 4.2095e-02\n",
      "[Contrastive] Epoch [171/300] - Train Loss: 0.2838, Val Loss: 0.2682\n",
      "[Epoch 172] grad norm (projector[0].weight): 4.0779e-02\n",
      "[Contrastive] Epoch [172/300] - Train Loss: 0.2847, Val Loss: 0.2699\n",
      "[Epoch 173] grad norm (projector[0].weight): 4.1156e-02\n",
      "[Contrastive] Epoch [173/300] - Train Loss: 0.2835, Val Loss: 0.2673\n",
      "[Epoch 174] grad norm (projector[0].weight): 4.5260e-02\n",
      "[Contrastive] Epoch [174/300] - Train Loss: 0.2838, Val Loss: 0.2719\n",
      "[Epoch 175] grad norm (projector[0].weight): 4.5244e-02\n",
      "[Contrastive] Epoch [175/300] - Train Loss: 0.2843, Val Loss: 0.2727\n",
      "[Epoch 176] grad norm (projector[0].weight): 5.7603e-02\n",
      "[Contrastive] Epoch [176/300] - Train Loss: 0.2839, Val Loss: 0.2687\n",
      "[Epoch 177] grad norm (projector[0].weight): 4.3543e-02\n",
      "[Contrastive] Epoch [177/300] - Train Loss: 0.2833, Val Loss: 0.2702\n",
      "[Epoch 178] grad norm (projector[0].weight): 3.9814e-02\n",
      "[Contrastive] Epoch [178/300] - Train Loss: 0.2832, Val Loss: 0.2732\n",
      "[Epoch 179] grad norm (projector[0].weight): 5.3945e-02\n",
      "[Contrastive] Epoch [179/300] - Train Loss: 0.2832, Val Loss: 0.2666\n",
      "[Epoch 180] grad norm (projector[0].weight): 4.2273e-02\n",
      "[Contrastive] Epoch [180/300] - Train Loss: 0.2837, Val Loss: 0.2670\n",
      "[Epoch 181] grad norm (projector[0].weight): 3.7157e-02\n",
      "[Contrastive] Epoch [181/300] - Train Loss: 0.2812, Val Loss: 0.2669\n",
      "[Epoch 182] grad norm (projector[0].weight): 4.5708e-02\n",
      "[Contrastive] Epoch [182/300] - Train Loss: 0.2821, Val Loss: 0.2658\n",
      "[Epoch 183] grad norm (projector[0].weight): 4.6489e-02\n",
      "[Contrastive] Epoch [183/300] - Train Loss: 0.2817, Val Loss: 0.2683\n",
      "[Epoch 184] grad norm (projector[0].weight): 4.1520e-02\n",
      "[Contrastive] Epoch [184/300] - Train Loss: 0.2816, Val Loss: 0.2675\n",
      "[Epoch 185] grad norm (projector[0].weight): 4.4113e-02\n",
      "[Contrastive] Epoch [185/300] - Train Loss: 0.2817, Val Loss: 0.2670\n",
      "[Epoch 186] grad norm (projector[0].weight): 4.6229e-02\n",
      "[Contrastive] Epoch [186/300] - Train Loss: 0.2811, Val Loss: 0.2675\n",
      "[Epoch 187] grad norm (projector[0].weight): 4.2859e-02\n",
      "[Contrastive] Epoch [187/300] - Train Loss: 0.2808, Val Loss: 0.2674\n",
      "[Epoch 188] grad norm (projector[0].weight): 4.3358e-02\n",
      "[Contrastive] Epoch [188/300] - Train Loss: 0.2803, Val Loss: 0.2676\n",
      "[Epoch 189] grad norm (projector[0].weight): 4.0544e-02\n",
      "[Contrastive] Epoch [189/300] - Train Loss: 0.2796, Val Loss: 0.2658\n",
      "[Epoch 190] grad norm (projector[0].weight): 4.5881e-02\n",
      "[Contrastive] Epoch [190/300] - Train Loss: 0.2792, Val Loss: 0.2650\n",
      "[Epoch 191] grad norm (projector[0].weight): 3.8554e-02\n",
      "[Contrastive] Epoch [191/300] - Train Loss: 0.2797, Val Loss: 0.2643\n",
      "[Epoch 192] grad norm (projector[0].weight): 4.3357e-02\n",
      "[Contrastive] Epoch [192/300] - Train Loss: 0.2792, Val Loss: 0.2640\n",
      "[Epoch 193] grad norm (projector[0].weight): 3.7303e-02\n",
      "[Contrastive] Epoch [193/300] - Train Loss: 0.2789, Val Loss: 0.2634\n",
      "[Epoch 194] grad norm (projector[0].weight): 3.0589e-02\n",
      "[Contrastive] Epoch [194/300] - Train Loss: 0.2794, Val Loss: 0.2649\n",
      "[Epoch 195] grad norm (projector[0].weight): 3.9061e-02\n",
      "[Contrastive] Epoch [195/300] - Train Loss: 0.2790, Val Loss: 0.2623\n",
      "[Epoch 196] grad norm (projector[0].weight): 3.8381e-02\n",
      "[Contrastive] Epoch [196/300] - Train Loss: 0.2785, Val Loss: 0.2665\n",
      "[Epoch 197] grad norm (projector[0].weight): 4.6080e-02\n",
      "[Contrastive] Epoch [197/300] - Train Loss: 0.2784, Val Loss: 0.2646\n",
      "[Epoch 198] grad norm (projector[0].weight): 3.4971e-02\n",
      "[Contrastive] Epoch [198/300] - Train Loss: 0.2786, Val Loss: 0.2649\n",
      "[Epoch 199] grad norm (projector[0].weight): 3.9343e-02\n",
      "[Contrastive] Epoch [199/300] - Train Loss: 0.2783, Val Loss: 0.2654\n",
      "[Epoch 200] grad norm (projector[0].weight): 3.8815e-02\n",
      "[Contrastive] Epoch [200/300] - Train Loss: 0.2780, Val Loss: 0.2648\n",
      "[Epoch 201] grad norm (projector[0].weight): 3.6447e-02\n",
      "[Contrastive] Epoch [201/300] - Train Loss: 0.2779, Val Loss: 0.2650\n",
      "[Epoch 202] grad norm (projector[0].weight): 4.1147e-02\n",
      "[Contrastive] Epoch [202/300] - Train Loss: 0.2779, Val Loss: 0.2640\n",
      "[Epoch 203] grad norm (projector[0].weight): 3.8727e-02\n",
      "[Contrastive] Epoch [203/300] - Train Loss: 0.2775, Val Loss: 0.2621\n",
      "[Epoch 204] grad norm (projector[0].weight): 3.9179e-02\n",
      "[Contrastive] Epoch [204/300] - Train Loss: 0.2775, Val Loss: 0.2612\n",
      "[Epoch 205] grad norm (projector[0].weight): 2.9863e-02\n",
      "[Contrastive] Epoch [205/300] - Train Loss: 0.2765, Val Loss: 0.2618\n",
      "[Epoch 206] grad norm (projector[0].weight): 3.9355e-02\n",
      "[Contrastive] Epoch [206/300] - Train Loss: 0.2775, Val Loss: 0.2641\n",
      "[Epoch 207] grad norm (projector[0].weight): 4.0535e-02\n",
      "[Contrastive] Epoch [207/300] - Train Loss: 0.2769, Val Loss: 0.2602\n",
      "[Epoch 208] grad norm (projector[0].weight): 3.6240e-02\n",
      "[Contrastive] Epoch [208/300] - Train Loss: 0.2762, Val Loss: 0.2641\n",
      "[Epoch 209] grad norm (projector[0].weight): 3.7503e-02\n",
      "[Contrastive] Epoch [209/300] - Train Loss: 0.2753, Val Loss: 0.2619\n",
      "[Epoch 210] grad norm (projector[0].weight): 3.4542e-02\n",
      "[Contrastive] Epoch [210/300] - Train Loss: 0.2764, Val Loss: 0.2604\n",
      "[Epoch 211] grad norm (projector[0].weight): 4.0080e-02\n",
      "[Contrastive] Epoch [211/300] - Train Loss: 0.2756, Val Loss: 0.2626\n",
      "[Epoch 212] grad norm (projector[0].weight): 4.2215e-02\n",
      "[Contrastive] Epoch [212/300] - Train Loss: 0.2758, Val Loss: 0.2656\n",
      "[Epoch 213] grad norm (projector[0].weight): 4.4645e-02\n",
      "[Contrastive] Epoch [213/300] - Train Loss: 0.2755, Val Loss: 0.2634\n",
      "[Epoch 214] grad norm (projector[0].weight): 3.8256e-02\n",
      "[Contrastive] Epoch [214/300] - Train Loss: 0.2755, Val Loss: 0.2632\n",
      "[Epoch 215] grad norm (projector[0].weight): 3.8821e-02\n",
      "[Contrastive] Epoch [215/300] - Train Loss: 0.2750, Val Loss: 0.2624\n",
      "[Epoch 216] grad norm (projector[0].weight): 3.7792e-02\n",
      "[Contrastive] Epoch [216/300] - Train Loss: 0.2753, Val Loss: 0.2635\n",
      "[Epoch 217] grad norm (projector[0].weight): 4.7372e-02\n",
      "[Contrastive] Epoch [217/300] - Train Loss: 0.2746, Val Loss: 0.2624\n",
      "[Epoch 218] grad norm (projector[0].weight): 3.5130e-02\n",
      "[Contrastive] Epoch [218/300] - Train Loss: 0.2753, Val Loss: 0.2597\n",
      "[Epoch 219] grad norm (projector[0].weight): 3.7096e-02\n",
      "[Contrastive] Epoch [219/300] - Train Loss: 0.2747, Val Loss: 0.2610\n",
      "[Epoch 220] grad norm (projector[0].weight): 3.8034e-02\n",
      "[Contrastive] Epoch [220/300] - Train Loss: 0.2746, Val Loss: 0.2612\n",
      "[Epoch 221] grad norm (projector[0].weight): 4.5176e-02\n",
      "[Contrastive] Epoch [221/300] - Train Loss: 0.2743, Val Loss: 0.2581\n",
      "[Epoch 222] grad norm (projector[0].weight): 4.5605e-02\n",
      "[Contrastive] Epoch [222/300] - Train Loss: 0.2729, Val Loss: 0.2593\n",
      "[Epoch 223] grad norm (projector[0].weight): 2.9298e-02\n",
      "[Contrastive] Epoch [223/300] - Train Loss: 0.2728, Val Loss: 0.2587\n",
      "[Epoch 224] grad norm (projector[0].weight): 3.2715e-02\n",
      "[Contrastive] Epoch [224/300] - Train Loss: 0.2734, Val Loss: 0.2618\n",
      "[Epoch 225] grad norm (projector[0].weight): 3.7417e-02\n",
      "[Contrastive] Epoch [225/300] - Train Loss: 0.2733, Val Loss: 0.2638\n",
      "[Epoch 226] grad norm (projector[0].weight): 4.4035e-02\n",
      "[Contrastive] Epoch [226/300] - Train Loss: 0.2727, Val Loss: 0.2609\n",
      "[Epoch 227] grad norm (projector[0].weight): 3.3657e-02\n",
      "[Contrastive] Epoch [227/300] - Train Loss: 0.2732, Val Loss: 0.2616\n",
      "[Epoch 228] grad norm (projector[0].weight): 4.2466e-02\n",
      "[Contrastive] Epoch [228/300] - Train Loss: 0.2732, Val Loss: 0.2585\n",
      "[Epoch 229] grad norm (projector[0].weight): 3.2845e-02\n",
      "[Contrastive] Epoch [229/300] - Train Loss: 0.2727, Val Loss: 0.2611\n",
      "[Epoch 230] grad norm (projector[0].weight): 3.5996e-02\n",
      "[Contrastive] Epoch [230/300] - Train Loss: 0.2720, Val Loss: 0.2612\n",
      "[Epoch 231] grad norm (projector[0].weight): 3.8789e-02\n",
      "[Contrastive] Epoch [231/300] - Train Loss: 0.2723, Val Loss: 0.2558\n",
      "[Epoch 232] grad norm (projector[0].weight): 3.4081e-02\n",
      "[Contrastive] Epoch [232/300] - Train Loss: 0.2723, Val Loss: 0.2607\n",
      "[Epoch 233] grad norm (projector[0].weight): 3.5321e-02\n",
      "[Contrastive] Epoch [233/300] - Train Loss: 0.2721, Val Loss: 0.2576\n",
      "[Epoch 234] grad norm (projector[0].weight): 3.2050e-02\n",
      "[Contrastive] Epoch [234/300] - Train Loss: 0.2719, Val Loss: 0.2578\n",
      "[Epoch 235] grad norm (projector[0].weight): 3.2153e-02\n",
      "[Contrastive] Epoch [235/300] - Train Loss: 0.2714, Val Loss: 0.2590\n",
      "[Epoch 236] grad norm (projector[0].weight): 3.3673e-02\n",
      "[Contrastive] Epoch [236/300] - Train Loss: 0.2718, Val Loss: 0.2586\n",
      "[Epoch 237] grad norm (projector[0].weight): 3.2328e-02\n",
      "[Contrastive] Epoch [237/300] - Train Loss: 0.2713, Val Loss: 0.2560\n",
      "[Epoch 238] grad norm (projector[0].weight): 3.2155e-02\n",
      "[Contrastive] Epoch [238/300] - Train Loss: 0.2712, Val Loss: 0.2588\n",
      "[Epoch 239] grad norm (projector[0].weight): 3.6577e-02\n",
      "[Contrastive] Epoch [239/300] - Train Loss: 0.2705, Val Loss: 0.2583\n",
      "[Epoch 240] grad norm (projector[0].weight): 3.5143e-02\n",
      "[Contrastive] Epoch [240/300] - Train Loss: 0.2706, Val Loss: 0.2554\n",
      "[Epoch 241] grad norm (projector[0].weight): 2.9424e-02\n",
      "[Contrastive] Epoch [241/300] - Train Loss: 0.2708, Val Loss: 0.2582\n",
      "[Epoch 242] grad norm (projector[0].weight): 3.6924e-02\n",
      "[Contrastive] Epoch [242/300] - Train Loss: 0.2711, Val Loss: 0.2582\n",
      "[Epoch 243] grad norm (projector[0].weight): 4.0255e-02\n",
      "[Contrastive] Epoch [243/300] - Train Loss: 0.2700, Val Loss: 0.2568\n",
      "[Epoch 244] grad norm (projector[0].weight): 2.7669e-02\n",
      "[Contrastive] Epoch [244/300] - Train Loss: 0.2696, Val Loss: 0.2565\n",
      "[Epoch 245] grad norm (projector[0].weight): 2.6128e-02\n",
      "[Contrastive] Epoch [245/300] - Train Loss: 0.2693, Val Loss: 0.2560\n",
      "[Epoch 246] grad norm (projector[0].weight): 3.2683e-02\n",
      "[Contrastive] Epoch [246/300] - Train Loss: 0.2699, Val Loss: 0.2571\n",
      "[Epoch 247] grad norm (projector[0].weight): 2.9925e-02\n",
      "[Contrastive] Epoch [247/300] - Train Loss: 0.2691, Val Loss: 0.2547\n",
      "[Epoch 248] grad norm (projector[0].weight): 3.8138e-02\n",
      "[Contrastive] Epoch [248/300] - Train Loss: 0.2700, Val Loss: 0.2583\n",
      "[Epoch 249] grad norm (projector[0].weight): 3.3220e-02\n",
      "[Contrastive] Epoch [249/300] - Train Loss: 0.2701, Val Loss: 0.2557\n",
      "[Epoch 250] grad norm (projector[0].weight): 2.9618e-02\n",
      "[Contrastive] Epoch [250/300] - Train Loss: 0.2691, Val Loss: 0.2545\n",
      "[Epoch 251] grad norm (projector[0].weight): 3.3328e-02\n",
      "[Contrastive] Epoch [251/300] - Train Loss: 0.2688, Val Loss: 0.2568\n",
      "[Epoch 252] grad norm (projector[0].weight): 3.1070e-02\n",
      "[Contrastive] Epoch [252/300] - Train Loss: 0.2689, Val Loss: 0.2563\n",
      "[Epoch 253] grad norm (projector[0].weight): 3.1080e-02\n",
      "[Contrastive] Epoch [253/300] - Train Loss: 0.2694, Val Loss: 0.2560\n",
      "[Epoch 254] grad norm (projector[0].weight): 3.3743e-02\n",
      "[Contrastive] Epoch [254/300] - Train Loss: 0.2689, Val Loss: 0.2541\n",
      "[Epoch 255] grad norm (projector[0].weight): 2.6965e-02\n",
      "[Contrastive] Epoch [255/300] - Train Loss: 0.2687, Val Loss: 0.2586\n",
      "[Epoch 256] grad norm (projector[0].weight): 2.9168e-02\n",
      "[Contrastive] Epoch [256/300] - Train Loss: 0.2684, Val Loss: 0.2529\n",
      "[Epoch 257] grad norm (projector[0].weight): 2.8928e-02\n",
      "[Contrastive] Epoch [257/300] - Train Loss: 0.2680, Val Loss: 0.2527\n",
      "[Epoch 258] grad norm (projector[0].weight): 2.9944e-02\n",
      "[Contrastive] Epoch [258/300] - Train Loss: 0.2684, Val Loss: 0.2542\n",
      "[Epoch 259] grad norm (projector[0].weight): 3.1520e-02\n",
      "[Contrastive] Epoch [259/300] - Train Loss: 0.2670, Val Loss: 0.2554\n",
      "[Epoch 260] grad norm (projector[0].weight): 3.2164e-02\n",
      "[Contrastive] Epoch [260/300] - Train Loss: 0.2679, Val Loss: 0.2569\n",
      "[Epoch 261] grad norm (projector[0].weight): 3.0586e-02\n",
      "[Contrastive] Epoch [261/300] - Train Loss: 0.2676, Val Loss: 0.2522\n",
      "[Epoch 262] grad norm (projector[0].weight): 3.2524e-02\n",
      "[Contrastive] Epoch [262/300] - Train Loss: 0.2678, Val Loss: 0.2531\n",
      "[Epoch 263] grad norm (projector[0].weight): 2.8657e-02\n",
      "[Contrastive] Epoch [263/300] - Train Loss: 0.2683, Val Loss: 0.2522\n",
      "[Epoch 264] grad norm (projector[0].weight): 3.9204e-02\n",
      "[Contrastive] Epoch [264/300] - Train Loss: 0.2663, Val Loss: 0.2534\n",
      "[Epoch 265] grad norm (projector[0].weight): 2.8733e-02\n",
      "[Contrastive] Epoch [265/300] - Train Loss: 0.2675, Val Loss: 0.2547\n",
      "[Epoch 266] grad norm (projector[0].weight): 2.8791e-02\n",
      "[Contrastive] Epoch [266/300] - Train Loss: 0.2670, Val Loss: 0.2554\n",
      "[Epoch 267] grad norm (projector[0].weight): 3.4397e-02\n",
      "[Contrastive] Epoch [267/300] - Train Loss: 0.2671, Val Loss: 0.2559\n",
      "[Epoch 268] grad norm (projector[0].weight): 3.6018e-02\n",
      "[Contrastive] Epoch [268/300] - Train Loss: 0.2669, Val Loss: 0.2503\n",
      "[Epoch 269] grad norm (projector[0].weight): 2.7334e-02\n",
      "[Contrastive] Epoch [269/300] - Train Loss: 0.2669, Val Loss: 0.2541\n",
      "[Epoch 270] grad norm (projector[0].weight): 2.8985e-02\n",
      "[Contrastive] Epoch [270/300] - Train Loss: 0.2670, Val Loss: 0.2520\n",
      "[Epoch 271] grad norm (projector[0].weight): 2.9763e-02\n",
      "[Contrastive] Epoch [271/300] - Train Loss: 0.2661, Val Loss: 0.2539\n",
      "[Epoch 272] grad norm (projector[0].weight): 2.8784e-02\n",
      "[Contrastive] Epoch [272/300] - Train Loss: 0.2658, Val Loss: 0.2537\n",
      "[Epoch 273] grad norm (projector[0].weight): 2.8705e-02\n",
      "[Contrastive] Epoch [273/300] - Train Loss: 0.2663, Val Loss: 0.2515\n",
      "[Epoch 274] grad norm (projector[0].weight): 2.8376e-02\n",
      "[Contrastive] Epoch [274/300] - Train Loss: 0.2659, Val Loss: 0.2509\n",
      "[Epoch 275] grad norm (projector[0].weight): 2.4364e-02\n",
      "[Contrastive] Epoch [275/300] - Train Loss: 0.2655, Val Loss: 0.2539\n",
      "[Epoch 276] grad norm (projector[0].weight): 3.9222e-02\n",
      "[Contrastive] Epoch [276/300] - Train Loss: 0.2663, Val Loss: 0.2506\n",
      "[Epoch 277] grad norm (projector[0].weight): 2.7156e-02\n",
      "[Contrastive] Epoch [277/300] - Train Loss: 0.2652, Val Loss: 0.2511\n",
      "[Epoch 278] grad norm (projector[0].weight): 2.8672e-02\n",
      "[Contrastive] Epoch [278/300] - Train Loss: 0.2656, Val Loss: 0.2492\n",
      "[Epoch 279] grad norm (projector[0].weight): 2.4152e-02\n",
      "[Contrastive] Epoch [279/300] - Train Loss: 0.2652, Val Loss: 0.2535\n",
      "[Epoch 280] grad norm (projector[0].weight): 2.9776e-02\n",
      "[Contrastive] Epoch [280/300] - Train Loss: 0.2655, Val Loss: 0.2513\n",
      "[Epoch 281] grad norm (projector[0].weight): 2.5135e-02\n",
      "[Contrastive] Epoch [281/300] - Train Loss: 0.2649, Val Loss: 0.2517\n",
      "[Epoch 282] grad norm (projector[0].weight): 2.3237e-02\n",
      "[Contrastive] Epoch [282/300] - Train Loss: 0.2651, Val Loss: 0.2516\n",
      "[Epoch 283] grad norm (projector[0].weight): 2.9904e-02\n",
      "[Contrastive] Epoch [283/300] - Train Loss: 0.2654, Val Loss: 0.2496\n",
      "[Epoch 284] grad norm (projector[0].weight): 2.0737e-02\n",
      "[Contrastive] Epoch [284/300] - Train Loss: 0.2647, Val Loss: 0.2520\n",
      "[Epoch 285] grad norm (projector[0].weight): 3.3387e-02\n",
      "[Contrastive] Epoch [285/300] - Train Loss: 0.2651, Val Loss: 0.2525\n",
      "[Epoch 286] grad norm (projector[0].weight): 2.7733e-02\n",
      "[Contrastive] Epoch [286/300] - Train Loss: 0.2642, Val Loss: 0.2492\n",
      "[Epoch 287] grad norm (projector[0].weight): 2.5044e-02\n",
      "[Contrastive] Epoch [287/300] - Train Loss: 0.2650, Val Loss: 0.2507\n",
      "[Epoch 288] grad norm (projector[0].weight): 3.1817e-02\n",
      "[Contrastive] Epoch [288/300] - Train Loss: 0.2647, Val Loss: 0.2582\n",
      "[Epoch 289] grad norm (projector[0].weight): 3.6422e-02\n",
      "[Contrastive] Epoch [289/300] - Train Loss: 0.2650, Val Loss: 0.2521\n",
      "[Epoch 290] grad norm (projector[0].weight): 2.3419e-02\n",
      "[Contrastive] Epoch [290/300] - Train Loss: 0.2638, Val Loss: 0.2534\n",
      "[Epoch 291] grad norm (projector[0].weight): 2.5931e-02\n",
      "[Contrastive] Epoch [291/300] - Train Loss: 0.2641, Val Loss: 0.2513\n",
      "[Epoch 292] grad norm (projector[0].weight): 2.3591e-02\n",
      "[Contrastive] Epoch [292/300] - Train Loss: 0.2637, Val Loss: 0.2500\n",
      "[Epoch 293] grad norm (projector[0].weight): 2.4961e-02\n",
      "[Contrastive] Epoch [293/300] - Train Loss: 0.2638, Val Loss: 0.2500\n",
      "[Epoch 294] grad norm (projector[0].weight): 2.5668e-02\n",
      "[Contrastive] Epoch [294/300] - Train Loss: 0.2639, Val Loss: 0.2503\n",
      "[Epoch 295] grad norm (projector[0].weight): 2.6058e-02\n",
      "[Contrastive] Epoch [295/300] - Train Loss: 0.2639, Val Loss: 0.2519\n",
      "[Epoch 296] grad norm (projector[0].weight): 2.8539e-02\n",
      "[Contrastive] Epoch [296/300] - Train Loss: 0.2635, Val Loss: 0.2507\n",
      "[Epoch 297] grad norm (projector[0].weight): 2.5192e-02\n",
      "[Contrastive] Epoch [297/300] - Train Loss: 0.2636, Val Loss: 0.2472\n",
      "[Epoch 298] grad norm (projector[0].weight): 1.9745e-02\n",
      "[Contrastive] Epoch [298/300] - Train Loss: 0.2623, Val Loss: 0.2479\n",
      "[Epoch 299] grad norm (projector[0].weight): 2.4560e-02\n",
      "[Contrastive] Epoch [299/300] - Train Loss: 0.2628, Val Loss: 0.2503\n",
      "[Epoch 300] grad norm (projector[0].weight): 2.5216e-02\n",
      "[Contrastive] Epoch [300/300] - Train Loss: 0.2629, Val Loss: 0.2503\n",
      "\n",
      "=== Supervised fine-tuning for classification (pf + images) ===\n",
      "[Classification] Epoch [1/100] - Train Loss: 0.1385, Train Acc: 0.9460, Val Loss: 0.1049, Val Acc: 0.9651\n",
      "[Classification] Epoch [2/100] - Train Loss: 0.0913, Train Acc: 0.9679, Val Loss: 0.0814, Val Acc: 0.9736\n",
      "[Classification] Epoch [3/100] - Train Loss: 0.0725, Train Acc: 0.9749, Val Loss: 0.0682, Val Acc: 0.9784\n",
      "[Classification] Epoch [4/100] - Train Loss: 0.0662, Train Acc: 0.9775, Val Loss: 0.0715, Val Acc: 0.9766\n",
      "[Classification] Epoch [5/100] - Train Loss: 0.0604, Train Acc: 0.9794, Val Loss: 0.0660, Val Acc: 0.9794\n",
      "[Classification] Epoch [6/100] - Train Loss: 0.0581, Train Acc: 0.9803, Val Loss: 0.0694, Val Acc: 0.9772\n",
      "[Classification] Epoch [7/100] - Train Loss: 0.0562, Train Acc: 0.9808, Val Loss: 0.0687, Val Acc: 0.9773\n",
      "[Classification] Epoch [8/100] - Train Loss: 0.0534, Train Acc: 0.9814, Val Loss: 0.0644, Val Acc: 0.9787\n",
      "[Classification] Epoch [9/100] - Train Loss: 0.0525, Train Acc: 0.9819, Val Loss: 0.0664, Val Acc: 0.9788\n",
      "[Classification] Epoch [10/100] - Train Loss: 0.0509, Train Acc: 0.9821, Val Loss: 0.0635, Val Acc: 0.9798\n",
      "[Classification] Epoch [11/100] - Train Loss: 0.0494, Train Acc: 0.9825, Val Loss: 0.0639, Val Acc: 0.9790\n",
      "[Classification] Epoch [12/100] - Train Loss: 0.0477, Train Acc: 0.9835, Val Loss: 0.0723, Val Acc: 0.9783\n",
      "[Classification] Epoch [13/100] - Train Loss: 0.0459, Train Acc: 0.9841, Val Loss: 0.0645, Val Acc: 0.9795\n",
      "[Classification] Epoch [14/100] - Train Loss: 0.0448, Train Acc: 0.9844, Val Loss: 0.0680, Val Acc: 0.9780\n",
      "[Classification] Epoch [15/100] - Train Loss: 0.0433, Train Acc: 0.9850, Val Loss: 0.0727, Val Acc: 0.9775\n",
      "[Classification] Epoch [16/100] - Train Loss: 0.0426, Train Acc: 0.9848, Val Loss: 0.0678, Val Acc: 0.9795\n",
      "[Classification] Epoch [17/100] - Train Loss: 0.0416, Train Acc: 0.9848, Val Loss: 0.0717, Val Acc: 0.9788\n",
      "[Classification] Epoch [18/100] - Train Loss: 0.0393, Train Acc: 0.9858, Val Loss: 0.0723, Val Acc: 0.9781\n",
      "[Classification] Epoch [19/100] - Train Loss: 0.0394, Train Acc: 0.9856, Val Loss: 0.0759, Val Acc: 0.9784\n",
      "[Classification] Epoch [20/100] - Train Loss: 0.0384, Train Acc: 0.9863, Val Loss: 0.0753, Val Acc: 0.9782\n",
      "[Classification] Epoch [21/100] - Train Loss: 0.0373, Train Acc: 0.9865, Val Loss: 0.0749, Val Acc: 0.9778\n",
      "[Classification] Epoch [22/100] - Train Loss: 0.0367, Train Acc: 0.9869, Val Loss: 0.0755, Val Acc: 0.9776\n",
      "[Classification] Epoch [23/100] - Train Loss: 0.0345, Train Acc: 0.9876, Val Loss: 0.0774, Val Acc: 0.9779\n",
      "[Classification] Epoch [24/100] - Train Loss: 0.0328, Train Acc: 0.9882, Val Loss: 0.0755, Val Acc: 0.9781\n",
      "[Classification] Epoch [25/100] - Train Loss: 0.0323, Train Acc: 0.9883, Val Loss: 0.0816, Val Acc: 0.9789\n",
      "[Classification] Epoch [26/100] - Train Loss: 0.0321, Train Acc: 0.9884, Val Loss: 0.0774, Val Acc: 0.9772\n",
      "[Classification] Epoch [27/100] - Train Loss: 0.0321, Train Acc: 0.9883, Val Loss: 0.0843, Val Acc: 0.9767\n",
      "[Classification] Epoch [28/100] - Train Loss: 0.0324, Train Acc: 0.9883, Val Loss: 0.0836, Val Acc: 0.9761\n",
      "[Classification] Epoch [29/100] - Train Loss: 0.0292, Train Acc: 0.9891, Val Loss: 0.0863, Val Acc: 0.9757\n",
      "[Classification] Epoch [30/100] - Train Loss: 0.0291, Train Acc: 0.9895, Val Loss: 0.0869, Val Acc: 0.9760\n",
      "[Classification] Epoch [31/100] - Train Loss: 0.0288, Train Acc: 0.9894, Val Loss: 0.0825, Val Acc: 0.9773\n",
      "[Classification] Epoch [32/100] - Train Loss: 0.0271, Train Acc: 0.9899, Val Loss: 0.0813, Val Acc: 0.9768\n",
      "[Classification] Epoch [33/100] - Train Loss: 0.0263, Train Acc: 0.9901, Val Loss: 0.0839, Val Acc: 0.9782\n",
      "[Classification] Epoch [34/100] - Train Loss: 0.0254, Train Acc: 0.9907, Val Loss: 0.0900, Val Acc: 0.9780\n",
      "[Classification] Epoch [35/100] - Train Loss: 0.0258, Train Acc: 0.9907, Val Loss: 0.0889, Val Acc: 0.9785\n",
      "[Classification] Epoch [36/100] - Train Loss: 0.0248, Train Acc: 0.9915, Val Loss: 0.0924, Val Acc: 0.9771\n",
      "[Classification] Epoch [37/100] - Train Loss: 0.0254, Train Acc: 0.9906, Val Loss: 0.0913, Val Acc: 0.9762\n",
      "[Classification] Epoch [38/100] - Train Loss: 0.0252, Train Acc: 0.9909, Val Loss: 0.0928, Val Acc: 0.9760\n",
      "[Classification] Epoch [39/100] - Train Loss: 0.0231, Train Acc: 0.9914, Val Loss: 0.0980, Val Acc: 0.9765\n",
      "[Classification] Epoch [40/100] - Train Loss: 0.0236, Train Acc: 0.9915, Val Loss: 0.0976, Val Acc: 0.9765\n",
      "Early stopping classification at epoch 40\n",
      "Identified 19545 correct labels out of 20000 labels\n",
      "Accuracy : 0.97725\n",
      "Precision: 0.9773018882691371\n",
      "Recall   : 0.9772278042398266\n",
      "F1 Score : 0.9772480109642385\n",
      "Labels are: ['GALAXY' 'STAR']\n",
      "Confusion Matrix:\n",
      " [[9679  269]\n",
      " [ 186 9866]]\n",
      "Classification_Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.97      0.98      9948\n",
      "           1       0.97      0.98      0.98     10052\n",
      "\n",
      "    accuracy                           0.98     20000\n",
      "   macro avg       0.98      0.98      0.98     20000\n",
      "weighted avg       0.98      0.98      0.98     20000\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([    0,     1,     2, ..., 19997, 19998, 19999]),\n",
       " 0.97725,\n",
       " 0.9773018882691371,\n",
       " 0.9772278042398266,\n",
       " array([[9679,  269],\n",
       "        [ 186, 9866]]),\n",
       " '              precision    recall  f1-score   support\\n\\n           0       0.98      0.97      0.98      9948\\n           1       0.97      0.98      0.98     10052\\n\\n    accuracy                           0.98     20000\\n   macro avg       0.98      0.98      0.98     20000\\nweighted avg       0.98      0.98      0.98     20000\\n')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "np.random.seed(69)\n",
    "import pandas as pd\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from linformer import LinformerCA\n",
    "from vit_pytorch.efficient_new import ViT  # updated file above\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# Make sure model save dir exists\n",
    "# ------------------------------------------------------------------\n",
    "os.makedirs(\"Trained_Models\", exist_ok=True)\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 1. Load and prepare data (same as your code)\n",
    "# ------------------------------------------------------------------\n",
    "X = np.load(\"/scratch/srinadb/Foundation/Dataset/Experiment1/X_exp1.npy\")\n",
    "dnnx = np.load(\"/scratch/srinadb/Foundation//Dataset/Experiment1/dnnx_exp1.npy\")\n",
    "objlist = np.load(\"/scratch/srinadb/Foundation//Dataset/Experiment1/objlist_exp1.npy\")\n",
    "y = np.load(\"/scratch/srinadb/Foundation//Dataset/Experiment1/y_exp1.npy\", allow_pickle=True)\n",
    "\n",
    "# Drop QSO\n",
    "idx_drop = np.where(y == \"QSO\")[0]\n",
    "X = np.delete(X, idx_drop, axis=0)\n",
    "dnnx = np.delete(dnnx, idx_drop, axis=0)\n",
    "y = np.delete(y, idx_drop, axis=0)\n",
    "objlist = np.delete(objlist, idx_drop, axis=0)\n",
    "\n",
    "# Factorize labels\n",
    "y, label_strings = pd.factorize(y, sort=True)\n",
    "print(\"\\nLabels:\", label_strings)\n",
    "\n",
    "# Train / val / test split\n",
    "zipX = list(zip(X, dnnx))\n",
    "zipy = list(zip(y, objlist))\n",
    "\n",
    "zipX_train, zipX_test, zipy_train, zipy_test = train_test_split(\n",
    "    zipX, zipy, test_size=0.125, random_state=42\n",
    ")\n",
    "zipX_train, zipX_val, zipy_train, zipy_val = train_test_split(\n",
    "    zipX_train, zipy_train, test_size=0.1428, random_state=42\n",
    ")\n",
    "\n",
    "X_train, dnnx_train = zip(*zipX_train)\n",
    "X_val, dnnx_val = zip(*zipX_val)\n",
    "X_test, dnnx_test = zip(*zipX_test)\n",
    "\n",
    "y_train, objlist_train = zip(*zipy_train)\n",
    "y_val, objlist_val = zip(*zipy_val)\n",
    "y_test, objlist_test = zip(*zipy_test)\n",
    "\n",
    "X_train = np.array(X_train)\n",
    "X_val = np.array(X_val)\n",
    "X_test = np.array(X_test)\n",
    "\n",
    "dnnx_train = np.array(dnnx_train)\n",
    "dnnx_val = np.array(dnnx_val)\n",
    "dnnx_test = np.array(dnnx_test)\n",
    "\n",
    "y_train = np.array(y_train)\n",
    "objlist_train = np.array(objlist_train)\n",
    "y_val = np.array(y_val)\n",
    "objlist_val = np.array(objlist_val)\n",
    "y_test = np.array(y_test)\n",
    "objlist_test = np.array(objlist_test)\n",
    "\n",
    "del(zipX, zipX_test, zipX_train, zipX_val, X, zipy, zipy_test, zipy_train, zipy_val, objlist)\n",
    "\n",
    "# Images to [N, C, H, W]\n",
    "X_train = X_train.transpose((0, 3, 1, 2))\n",
    "X_val = X_val.transpose((0, 3, 1, 2))\n",
    "X_test = X_test.transpose((0, 3, 1, 2))\n",
    "\n",
    "print('\\n')\n",
    "print('Train shape:', X_train.shape)\n",
    "print('Val shape  :', X_val.shape)\n",
    "print('Test shape :', X_test.shape)\n",
    "\n",
    "# Feature dimension for pf (used to create dummy zeros in SimCLR)\n",
    "PF_DIM = dnnx_train.shape[1]\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 2. Metrics helper\n",
    "# ------------------------------------------------------------------\n",
    "def get_metrics(y_pred, y_test, labels, to_print=True):\n",
    "    correct_labels = np.where(y_pred == y_test)[0]\n",
    "    accuracy = metrics.accuracy_score(y_test, y_pred)\n",
    "    precision = metrics.precision_score(y_test, y_pred, average='macro')\n",
    "    recall = metrics.recall_score(y_test, y_pred, average='macro')\n",
    "    f1score = metrics.f1_score(y_test, y_pred, average='macro')\n",
    "    confusion_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
    "    classification_report = metrics.classification_report(y_test, y_pred)\n",
    "\n",
    "    if to_print:\n",
    "        print(\"Identified {} correct labels out of {} labels\".format(len(correct_labels), y_test.shape[0]))\n",
    "        print(\"Accuracy :\", accuracy)\n",
    "        print(\"Precision:\", precision)\n",
    "        print(\"Recall   :\", recall)\n",
    "        print(\"F1 Score :\", f1score)\n",
    "        print(f\"Labels are: {labels}\")\n",
    "        print(\"Confusion Matrix:\\n\", confusion_matrix)\n",
    "        print(\"Classification_Report:\\n\", classification_report)\n",
    "\n",
    "    return (correct_labels, accuracy, precision, recall, confusion_matrix, classification_report)\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 3. Dataset classes\n",
    "# ------------------------------------------------------------------\n",
    "class SGContrastiveData(Dataset):\n",
    "    \"\"\"\n",
    "    For SELF-SUPERVISED contrastive learning:\n",
    "    returns (pf, img_view1, img_view2) but pf is IGNORED in SimCLR.\n",
    "    \"\"\"\n",
    "    def __init__(self, x_pf, x_img, transform=None):\n",
    "        self.x_pf = torch.tensor(x_pf, dtype=torch.float32)   # [N, PF_DIM]\n",
    "        self.x_img = torch.tensor(x_img, dtype=torch.float32) # [N, C, H, W]\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.x_pf.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        pf = self.x_pf[idx]   # kept for consistency, but not used in SSL\n",
    "        img = self.x_img[idx] # [C, H, W]\n",
    "\n",
    "        if self.transform:\n",
    "            img_view1 = self.transform(img)\n",
    "            img_view2 = self.transform(img)\n",
    "        else:\n",
    "            img_view1 = img\n",
    "            img_view2 = img\n",
    "\n",
    "        return pf, img_view1, img_view2\n",
    "\n",
    "\n",
    "class SGData(Dataset):\n",
    "    \"\"\"\n",
    "    For SUPERVISED classification: (pf, img, label).\n",
    "    Fine-tuning will use BOTH pf + images here.\n",
    "    \"\"\"\n",
    "    def __init__(self, x1, x2, y, transform=None):\n",
    "        self.n_samples = x2.shape[0]\n",
    "        self.x1 = torch.tensor(x1, dtype=torch.float32)\n",
    "        self.x2 = torch.tensor(x2, dtype=torch.float32)\n",
    "        self.y = torch.tensor(y)\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.n_samples\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        inputs_pf, inputs_imgs, targets = self.x1[i], self.x2[i], self.y[i]\n",
    "\n",
    "        if self.transform:\n",
    "            inputs_imgs = self.transform(inputs_imgs)\n",
    "\n",
    "        return inputs_pf, inputs_imgs, targets\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 4. Data augmentation & loaders\n",
    "# ------------------------------------------------------------------\n",
    "image_transform = transforms.Compose([\n",
    "    transforms.RandomRotation(180),\n",
    "    transforms.RandomAffine(degrees=0, translate=(0.1, 0.1)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomVerticalFlip(),\n",
    "])\n",
    "\n",
    "# Contrastive datasets (SSL on images only; pf ignored later)\n",
    "contrastive_train_dataset = SGContrastiveData(dnnx_train, X_train, transform=image_transform)\n",
    "contrastive_val_dataset   = SGContrastiveData(dnnx_val,   X_val,   transform=image_transform)\n",
    "\n",
    "contrastive_train_loader = DataLoader(contrastive_train_dataset, batch_size=1024, shuffle=True,  num_workers=8)\n",
    "contrastive_val_loader   = DataLoader(contrastive_val_dataset,   batch_size=1024, shuffle=False, num_workers=4)\n",
    "\n",
    "# Classification datasets (pf + image)\n",
    "train_dataset = SGData(dnnx_train, X_train, y_train, transform=image_transform)\n",
    "val_dataset   = SGData(dnnx_val,   X_val,   y_val,   transform=image_transform)\n",
    "test_dataset  = SGData(dnnx_test,  X_test,  y_test,  transform=None)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=512, shuffle=True,  num_workers=8)\n",
    "val_loader   = DataLoader(val_dataset,   batch_size=512, shuffle=False, num_workers=4)\n",
    "test_loader  = DataLoader(test_dataset,  batch_size=512, shuffle=False, num_workers=4)\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 5. Model, contrastive wrapper & loss\n",
    "# ------------------------------------------------------------------\n",
    "n_classes = 2\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device:\", device)\n",
    "\n",
    "in_channels = X_train.shape[1]\n",
    "\n",
    "PATCH_SIZE = 4\n",
    "DEPTH      = 12\n",
    "HIDDEN_DIM = 64\n",
    "K_DIM      = 64\n",
    "NUM_HEADS  = 8\n",
    "LIN_DROPOUT = 0.1\n",
    "\n",
    "LR_CONTRASTIVE    = 3e-3   # slightly higher LR for contrastive\n",
    "LR_CLASSIFICATION = 1e-3\n",
    "PROJ_DIM          = 128\n",
    "\n",
    "seq_len = int((32 / PATCH_SIZE) ** 2) + 1  # num_patches + cls\n",
    "\n",
    "# Linformer Cross-Attention\n",
    "lin = LinformerCA(\n",
    "    dim=HIDDEN_DIM,\n",
    "    seq_len=seq_len,\n",
    "    depth=DEPTH,\n",
    "    k=K_DIM,\n",
    "    heads=NUM_HEADS,\n",
    "    dim_head=None,\n",
    "    one_kv_head=False,\n",
    "    share_kv=False,\n",
    "    reversible=False,\n",
    "    dropout=LIN_DROPOUT\n",
    ")\n",
    "\n",
    "# ViT backbone (shared)\n",
    "backbone = ViT(\n",
    "    image_size=32,\n",
    "    patch_size=PATCH_SIZE,\n",
    "    num_classes=n_classes,\n",
    "    dim=HIDDEN_DIM,\n",
    "    transformer=lin,\n",
    "    pool='cls',\n",
    "    channels=in_channels\n",
    ").to(device)\n",
    "\n",
    "class ContrastiveModel(nn.Module):\n",
    "    \"\"\"\n",
    "    For SimCLR: use ONLY images.\n",
    "    pf is replaced by zeros so SSL cannot cheat using pf features.\n",
    "    \"\"\"\n",
    "    def __init__(self, backbone, proj_dim=128):\n",
    "        super().__init__()\n",
    "        self.backbone = backbone\n",
    "        self.projector = nn.Sequential(\n",
    "            nn.Linear(HIDDEN_DIM, proj_dim),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(proj_dim, proj_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, img):\n",
    "        # img: [B, C, H, W]\n",
    "        B = img.size(0)\n",
    "        pf_dummy = torch.zeros(B, PF_DIM, device=img.device)  # dummy pf\n",
    "        h = self.backbone(pf_dummy, img, return_embedding=True)  # [B, HIDDEN_DIM]\n",
    "        z = self.projector(h)                                   # [B, proj_dim]\n",
    "        return h, z\n",
    "\n",
    "contrastive_model = ContrastiveModel(backbone, proj_dim=PROJ_DIM).to(device)\n",
    "\n",
    "# Standard SimCLR / NT-Xent loss (2 views)\n",
    "class NTXentLoss(nn.Module):\n",
    "    def __init__(self, temperature=0.07):\n",
    "        super().__init__()\n",
    "        self.temperature = temperature\n",
    "\n",
    "    def forward(self, z1, z2):\n",
    "        # normalize\n",
    "        z1 = F.normalize(z1, dim=1)\n",
    "        z2 = F.normalize(z2, dim=1)\n",
    "        B = z1.size(0)\n",
    "\n",
    "        z = torch.cat([z1, z2], dim=0)  # [2B, D]\n",
    "        sim = torch.matmul(z, z.T) / self.temperature  # [2B, 2B]\n",
    "\n",
    "        # mask out self\n",
    "        mask = torch.eye(2 * B, device=z.device, dtype=torch.bool)\n",
    "        sim = sim.masked_fill(mask, -9e15)\n",
    "\n",
    "        # positive for i: i+B (for first B) and i-B (for second B)\n",
    "        pos_indices = torch.cat([\n",
    "            torch.arange(B, 2 * B, device=z.device),\n",
    "            torch.arange(0, B, device=z.device)\n",
    "        ])\n",
    "        pos_sim = sim[torch.arange(2 * B, device=z.device), pos_indices]\n",
    "\n",
    "        # log-sum-exp over all others\n",
    "        logsumexp = torch.logsumexp(sim, dim=1)\n",
    "\n",
    "        loss = -pos_sim + logsumexp\n",
    "        return loss.mean()\n",
    "\n",
    "contrastive_loss_fn = NTXentLoss(temperature=0.1)\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 6. Self-supervised contrastive pretraining (IMAGE-ONLY SimCLR)\n",
    "# ------------------------------------------------------------------\n",
    "contrastive_optimizer = optim.Adam(contrastive_model.parameters(), lr=LR_CONTRASTIVE)\n",
    "\n",
    "contrastive_epochs = 300\n",
    "patience_contrastive = 20\n",
    "best_contrastive_val_loss = float('inf')\n",
    "best_contrastive_state = None\n",
    "counter = 0\n",
    "\n",
    "contrastive_train_loss_arr = []\n",
    "contrastive_val_loss_arr = []\n",
    "\n",
    "print(\"\\n=== Self-supervised contrastive pretraining (IMAGE ONLY) ===\")\n",
    "for epoch in range(contrastive_epochs):\n",
    "    # ---- TRAIN ----\n",
    "    contrastive_model.train()\n",
    "    total_train_loss = 0.0\n",
    "\n",
    "    for batch_idx, (pf, img_v1, img_v2) in enumerate(contrastive_train_loader):\n",
    "        # pf is ignored intentionally\n",
    "        img_v1 = img_v1.to(device)\n",
    "        img_v2 = img_v2.to(device)\n",
    "\n",
    "        _, z1 = contrastive_model(img_v1)  # [B, D]\n",
    "        _, z2 = contrastive_model(img_v2)  # [B, D]\n",
    "\n",
    "        loss = contrastive_loss_fn(z1, z2)\n",
    "\n",
    "        contrastive_optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "        # Optional debug: gradient norm\n",
    "        if batch_idx == 0:\n",
    "            with torch.no_grad():\n",
    "                gnorm = contrastive_model.projector[0].weight.grad.norm().item()\n",
    "            print(f\"[Epoch {epoch+1}] grad norm (projector[0].weight): {gnorm:.4e}\")\n",
    "\n",
    "        contrastive_optimizer.step()\n",
    "        total_train_loss += loss.item()\n",
    "\n",
    "    train_loss = total_train_loss / len(contrastive_train_loader)\n",
    "    contrastive_train_loss_arr.append(train_loss)\n",
    "\n",
    "    # ---- VALIDATION ----\n",
    "    contrastive_model.eval()\n",
    "    total_val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for pf, img_v1, img_v2 in contrastive_val_loader:\n",
    "            img_v1 = img_v1.to(device)\n",
    "            img_v2 = img_v2.to(device)\n",
    "\n",
    "            _, z1 = contrastive_model(img_v1)\n",
    "            _, z2 = contrastive_model(img_v2)\n",
    "\n",
    "            loss = contrastive_loss_fn(z1, z2)\n",
    "            total_val_loss += loss.item()\n",
    "\n",
    "    val_loss = total_val_loss / len(contrastive_val_loader)\n",
    "    contrastive_val_loss_arr.append(val_loss)\n",
    "\n",
    "    print(f\"[Contrastive] Epoch [{epoch+1}/{contrastive_epochs}] - \"\n",
    "          f\"Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}\")\n",
    "\n",
    "    # Early stopping on contrastive val loss\n",
    "    if val_loss < best_contrastive_val_loss:\n",
    "        best_contrastive_val_loss = val_loss\n",
    "        best_contrastive_state = contrastive_model.state_dict()\n",
    "        counter = 0\n",
    "        torch.save(best_contrastive_state, \"Trained_Models/EX1_SG_MargFormer_Contrastive_Pretrain.pth\")\n",
    "    else:\n",
    "        counter += 1\n",
    "\n",
    "    if counter >= patience_contrastive:\n",
    "        print(f\"Early stopping contrastive pretraining at epoch {epoch+1}\")\n",
    "        break\n",
    "\n",
    "# Load best contrastive weights\n",
    "if best_contrastive_state is not None:\n",
    "    contrastive_model.load_state_dict(best_contrastive_state)\n",
    "\n",
    "# Plot contrastive loss curves\n",
    "epochs_contrastive_range = range(1, len(contrastive_train_loss_arr) + 1)\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(epochs_contrastive_range, contrastive_train_loss_arr, label='Train Loss')\n",
    "plt.plot(epochs_contrastive_range, contrastive_val_loss_arr, label='Val Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Contrastive Loss')\n",
    "plt.title('Contrastive Pretraining Loss (Image-only SimCLR)')\n",
    "plt.legend()\n",
    "plt.savefig(\"Trained_Models/EX1_SG_MargFormer_Contrastive_Loss.png\")\n",
    "plt.close()\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 7. Supervised fine-tuning for classification (pf + images)\n",
    "# ------------------------------------------------------------------\n",
    "print(\"\\n=== Supervised fine-tuning for classification (pf + images) ===\")\n",
    "\n",
    "model = contrastive_model.backbone  # reuse pretrained backbone\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=LR_CLASSIFICATION)\n",
    "\n",
    "train_loss_arr = []\n",
    "train_accuracy_arr = []\n",
    "val_loss_arr = []\n",
    "val_accuracy_arr = []\n",
    "\n",
    "patience_cls = 30\n",
    "best_val_loss = float('inf')\n",
    "best_model_state = None\n",
    "counter = 0\n",
    "max_epochs_cls = 100\n",
    "\n",
    "for epoch in range(max_epochs_cls):\n",
    "    # ---- TRAIN ----\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    correct_train = 0\n",
    "    total_train = 0\n",
    "\n",
    "    for batch_x1, batch_x2, batch_y in train_loader:\n",
    "        batch_x1 = batch_x1.to(device)  # pf (USED here)\n",
    "        batch_x2 = batch_x2.to(device)  # img\n",
    "        batch_y  = batch_y.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = model(batch_x1, batch_x2)  # logits using pf + img\n",
    "        loss = criterion(output, batch_y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        _, predicted = output.max(1)\n",
    "        total_train += batch_y.size(0)\n",
    "        correct_train += predicted.eq(batch_y).sum().item()\n",
    "\n",
    "    train_loss /= len(train_loader)\n",
    "    train_accuracy = correct_train / total_train\n",
    "    train_loss_arr.append(train_loss)\n",
    "    train_accuracy_arr.append(train_accuracy)\n",
    "\n",
    "    # ---- VALIDATION ----\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    correct_val = 0\n",
    "    total_val = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_x1, batch_x2, batch_y in val_loader:\n",
    "            batch_x1 = batch_x1.to(device)\n",
    "            batch_x2 = batch_x2.to(device)\n",
    "            batch_y  = batch_y.to(device)\n",
    "\n",
    "            output = model(batch_x1, batch_x2)\n",
    "            loss = criterion(output, batch_y)\n",
    "            val_loss += loss.item()\n",
    "\n",
    "            _, predicted = output.max(1)\n",
    "            total_val += batch_y.size(0)\n",
    "            correct_val += predicted.eq(batch_y).sum().item()\n",
    "\n",
    "    val_loss /= len(val_loader)\n",
    "    val_accuracy = correct_val / total_val\n",
    "    val_loss_arr.append(val_loss)\n",
    "    val_accuracy_arr.append(val_accuracy)\n",
    "\n",
    "    print(f\"[Classification] Epoch [{epoch+1}/{max_epochs_cls}] - \"\n",
    "          f\"Train Loss: {train_loss:.4f}, Train Acc: {train_accuracy:.4f}, \"\n",
    "          f\"Val Loss: {val_loss:.4f}, Val Acc: {val_accuracy:.4f}\")\n",
    "\n",
    "    # Early stopping on val loss\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        best_model_state = model.state_dict()\n",
    "        counter = 0\n",
    "        torch.save(best_model_state, \"Trained_Models/EX1_SG_MargFormer_Contrastive_Finetuned.pth\")\n",
    "    else:\n",
    "        counter += 1\n",
    "\n",
    "    if counter >= patience_cls:\n",
    "        print(f\"Early stopping classification at epoch {epoch+1}\")\n",
    "        if best_model_state is not None:\n",
    "            model.load_state_dict(best_model_state)\n",
    "        break\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 8. Plots for classification\n",
    "# ------------------------------------------------------------------\n",
    "epoch_range = range(1, len(train_loss_arr) + 1)\n",
    "\n",
    "# Accuracy plot\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(epoch_range, train_accuracy_arr, label='Train Accuracy')\n",
    "plt.plot(epoch_range, val_accuracy_arr, label='Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Classification Accuracy (pf + image)')\n",
    "plt.legend()\n",
    "plt.savefig(\"Trained_Models/EX1_SG_MargFormer_Contrastive_Accuracy.png\")\n",
    "plt.close()\n",
    "\n",
    "# Loss plot\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(epoch_range, train_loss_arr, label='Train Loss')\n",
    "plt.plot(epoch_range, val_loss_arr, label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Classification Loss (pf + image)')\n",
    "plt.legend()\n",
    "plt.savefig(\"Trained_Models/EX1_SG_MargFormer_Contrastive_Loss_Class.png\")\n",
    "plt.close()\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 9. Final test evaluation\n",
    "# ------------------------------------------------------------------\n",
    "model.eval()\n",
    "y_pred_list = []\n",
    "y_true_list = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_x1, batch_x2, batch_y in test_loader:\n",
    "        batch_x1 = batch_x1.to(device)  # pf\n",
    "        batch_x2 = batch_x2.to(device)  # img\n",
    "\n",
    "        outputs = model(batch_x1, batch_x2)\n",
    "        preds = outputs.argmax(dim=1).cpu().numpy()\n",
    "\n",
    "        y_pred_list.append(preds)\n",
    "        y_true_list.append(batch_y.numpy())\n",
    "\n",
    "y_pred = np.concatenate(y_pred_list)\n",
    "y_true = np.concatenate(y_true_list)\n",
    "\n",
    "get_metrics(y_pred, y_true, label_strings, to_print=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5a53b6ea-2a2e-4d97-9222-e9388eca3fe0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19022, 5, 32, 32)\n",
      "\n",
      "=== Experiment 3 (Star/Galaxy) metrics ===\n",
      "Identified 17340 correct labels out of 19022 labels\n",
      "Accuracy : 0.9115760698138997\n",
      "Precision: 0.9204796526098169\n",
      "Recall   : 0.9115760698138997\n",
      "F1 Score : 0.9111054883961933\n",
      "Labels are: ['GALAXY' 'STAR']\n",
      "Confusion Matrix:\n",
      " [[9362  149]\n",
      " [1533 7978]]\n",
      "Classification_Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.98      0.92      9511\n",
      "           1       0.98      0.84      0.90      9511\n",
      "\n",
      "    accuracy                           0.91     19022\n",
      "   macro avg       0.92      0.91      0.91     19022\n",
      "weighted avg       0.92      0.91      0.91     19022\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([    0,     1,     2, ..., 19019, 19020, 19021]),\n",
       " 0.9115760698138997,\n",
       " 0.9204796526098169,\n",
       " 0.9115760698138997,\n",
       " array([[9362,  149],\n",
       "        [1533, 7978]]),\n",
       " '              precision    recall  f1-score   support\\n\\n           0       0.86      0.98      0.92      9511\\n           1       0.98      0.84      0.90      9511\\n\\n    accuracy                           0.91     19022\\n   macro avg       0.92      0.91      0.91     19022\\nweighted avg       0.92      0.91      0.91     19022\\n')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dnnx_sg = np.load(\"/scratch/srinadb/Foundation/Dataset/Experiment3/dnnx_sg_exp3.npy\")\n",
    "X_sg    = np.load(\"/scratch/srinadb/Foundation/Dataset/Experiment3/X_sg_exp3.npy\")\n",
    "X_sg    = X_sg.transpose((0, 3, 1, 2))   # -> [N, C, H, W]\n",
    "\n",
    "y_sg = np.load(\"/scratch/srinadb/Foundation/Dataset/Experiment3/y_sg_exp3.npy\")\n",
    "y_sg = np.argmax(y_sg, axis=1)           # from one-hot to class indices\n",
    "\n",
    "print(X_sg.shape)\n",
    "\n",
    "# Same setup as training\n",
    "n_classes = 2\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "in_channels = X_sg.shape[1]   # should match X_train.shape[1]\n",
    "\n",
    "PATCH_SIZE  = 4\n",
    "DEPTH       = 12\n",
    "HIDDEN_DIM  = 64\n",
    "K_DIM       = 64\n",
    "NUM_HEADS   = 8\n",
    "LIN_DROPOUT = 0.1\n",
    "\n",
    "seq_len = int((32 / PATCH_SIZE) ** 2) + 1  # num_patches + cls\n",
    "\n",
    "# Recreate Linformer + ViT\n",
    "lin_eval = LinformerCA(\n",
    "    dim=HIDDEN_DIM,\n",
    "    seq_len=seq_len,\n",
    "    depth=DEPTH,\n",
    "    k=K_DIM,\n",
    "    heads=NUM_HEADS,\n",
    "    dim_head=None,\n",
    "    one_kv_head=False,\n",
    "    share_kv=False,\n",
    "    reversible=False,\n",
    "    dropout=LIN_DROPOUT\n",
    ")\n",
    "\n",
    "model_eval = ViT(\n",
    "    image_size=32,\n",
    "    patch_size=PATCH_SIZE,\n",
    "    num_classes=n_classes,\n",
    "    dim=HIDDEN_DIM,\n",
    "    transformer=lin_eval,\n",
    "    pool='cls',\n",
    "    channels=in_channels\n",
    ").to(device)\n",
    "\n",
    "# Load the fine-tuned weights\n",
    "checkpoint_path = \"Trained_Models/EX1_SG_MargFormer_Contrastive_Finetuned.pth\"\n",
    "state_dict = torch.load(checkpoint_path, map_location=device)\n",
    "model_eval.load_state_dict(state_dict)\n",
    "model_eval.eval()\n",
    "\n",
    "# Reuse SGData from your script\n",
    "class SGData(Dataset):\n",
    "    def __init__(self, x1, x2, y, transform=None):\n",
    "        self.n_samples = x2.shape[0]\n",
    "        self.x1 = torch.tensor(x1, dtype=torch.float32)\n",
    "        self.x2 = torch.tensor(x2, dtype=torch.float32)\n",
    "        self.y  = torch.tensor(y,  dtype=torch.long)\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.n_samples\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        inputs_pf, inputs_imgs, targets = self.x1[i], self.x2[i], self.y[i]\n",
    "        if self.transform:\n",
    "            inputs_imgs = self.transform(inputs_imgs)\n",
    "        return inputs_pf, inputs_imgs, targets\n",
    "\n",
    "# Create dataset & loader for Experiment 3\n",
    "sg_dataset = SGData(dnnx_sg, X_sg, y_sg, transform=None)\n",
    "sg_loader  = DataLoader(sg_dataset, batch_size=512, shuffle=False, num_workers=4)\n",
    "\n",
    "# Same get_metrics as in your script\n",
    "def get_metrics(y_pred, y_test, labels, to_print=True):\n",
    "    correct_labels = np.where(y_pred == y_test)[0]\n",
    "    accuracy = metrics.accuracy_score(y_test, y_pred)\n",
    "    precision = metrics.precision_score(y_test, y_pred, average='macro')\n",
    "    recall = metrics.recall_score(y_test, y_pred, average='macro')\n",
    "    f1score = metrics.f1_score(y_test, y_pred, average='macro')\n",
    "    confusion_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
    "    classification_report = metrics.classification_report(y_test, y_pred)\n",
    "\n",
    "    if to_print:\n",
    "        print(\"Identified {} correct labels out of {} labels\".format(len(correct_labels), y_test.shape[0]))\n",
    "        print(\"Accuracy :\", accuracy)\n",
    "        print(\"Precision:\", precision)\n",
    "        print(\"Recall   :\", recall)\n",
    "        print(\"F1 Score :\", f1score)\n",
    "        print(f\"Labels are: {labels}\")\n",
    "        print(\"Confusion Matrix:\\n\", confusion_matrix)\n",
    "        print(\"Classification_Report:\\n\", classification_report)\n",
    "\n",
    "    return (correct_labels, accuracy, precision, recall, confusion_matrix, classification_report)\n",
    "\n",
    "# Inference loop\n",
    "model_eval.eval()\n",
    "y_pred_list = []\n",
    "y_true_list = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_pf, batch_imgs, batch_y in sg_loader:\n",
    "        batch_pf   = batch_pf.to(device)\n",
    "        batch_imgs = batch_imgs.to(device)\n",
    "\n",
    "        outputs = model_eval(batch_pf, batch_imgs)   # logits [B,2]\n",
    "        preds = outputs.argmax(dim=1).cpu().numpy()\n",
    "\n",
    "        y_pred_list.append(preds)\n",
    "        y_true_list.append(batch_y.numpy())\n",
    "\n",
    "y_pred_sg = np.concatenate(y_pred_list)\n",
    "y_true_sg = np.concatenate(y_true_list)\n",
    "\n",
    "print(\"\\n=== Experiment 3 (Star/Galaxy) metrics ===\")\n",
    "get_metrics(y_pred_sg, y_true_sg, label_strings, to_print=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b43960ca-11f1-4dde-8d2a-ae802006c3cf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "# Confusion matrix using your prediction variables\n",
    "cf_matrix = metrics.confusion_matrix(y_true_sg, y_pred_sg)\n",
    "cf_matrix_percentage = metrics.confusion_matrix(\n",
    "    y_true_sg, y_pred_sg, normalize='true'\n",
    ")\n",
    "\n",
    "# Flatten and create labels with percentage + count\n",
    "group_counts = [\"{0:0.0f}\".format(value) for value in cf_matrix.flatten()]\n",
    "group_percentages = [\"{0:.2%}\".format(value) for value in cf_matrix_percentage.flatten()]\n",
    "labels = [f\"{v1}\\n({v2})\" for v1, v2 in zip(group_percentages, group_counts)]\n",
    "labels = np.asarray(labels).reshape(2, 2)\n",
    "\n",
    "# Plot\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "sns.heatmap(cf_matrix, annot=labels, fmt='', cmap='Blues', ax=ax)\n",
    "\n",
    "ax.set_xlabel('Predicted', fontsize=14, weight='bold')\n",
    "ax.set_ylabel('Actual', fontsize=14, weight='bold')\n",
    "\n",
    "# Adjust these tick labels to match your class order (0 -> GALAXY, 1 -> STAR)\n",
    "ax.xaxis.set_ticklabels(['GALAXY', 'STAR'], fontsize=14, weight='bold')\n",
    "ax.yaxis.set_ticklabels(['GALAXY', 'STAR'], fontsize=14, weight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"Trained_Models/EX3_SG_MargFormerSCLR_CM.png\")\n",
    "plt.show()\n",
    "# plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6043b280-8982-4d18-8823-37fee9ec85b7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "srinadh_astro",
   "language": "python",
   "name": "srinadh_astro"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
